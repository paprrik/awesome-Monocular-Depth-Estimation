# awesome-Monocular-Depth-Estimation [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

[Thanks.](https://github.com/Yochengliu/awesome-point-cloud-analysis)  

<h1> 


```diff
- Recent papers 
```

</h1>&emsp;

Statistics: :fire: code is available & stars >= 100 &emsp;|&emsp; :star: citation >= 50



---
## 2021

- [[IJCV](https://arxiv.org/pdf/2105.11610.pdf)] Unsupervised Scale-consistent Depth Learning from Video [[code](https://github.com/JiawangBian/SC-SfMLearner-Release)]![Github stars](https://img.shields.io/github/stars/JiawangBian/SC-SfMLearner-Release.svg)  (Extended version of [NeurIPS 2019](https://papers.nips.cc/paper/8299-unsupervised-scale-consistent-depth-and-ego-motion-learning-from-monocular-video.pdf)) [[Project webpage](https://jwbian.net/sc-sfmlearner)] :fire:
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.pdf)] AdaBins: Depth Estimation Using Adaptive Bins [[code](https://github.com/shariqfarooq123/AdaBins)]![Github stars](https://img.shields.io/github/stars/shariqfarooq123/AdaBins.svg) :fire:
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Gonzalez_PLADE-Net_Towards_Pixel-Level_Accuracy_for_Self-Supervised_Single-View_Depth_Estimation_With_CVPR_2021_paper.pdf)] PLADE-Net: Towards Pixel-Level Accuracy for Self-Supervised Single-View Depth Estimation with Neural Positional Encoding and Distilled Matting Loss
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Guizilini_Sparse_Auxiliary_Networks_for_Unified_Monocular_Depth_Prediction_and_Completion_CVPR_2021_paper.pdf)] Sparse Auxiliary Networks for Unified Monocular Depth Prediction and Completion
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Jiao_EffiScene_Efficient_Per-Pixel_Rigidity_Inference_for_Unsupervised_Joint_Learning_of_CVPR_2021_paper.pdf)] EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Ramamonjisoa_Single_Image_Depth_Prediction_With_Wavelet_Decomposition_CVPR_2021_paper.pdf)] Single Image Depth Prediction with Wavelet Decomposition [[code](https://github.com/nianticlabs/wavelet-monodepth)]![Github stars](https://img.shields.io/github/stars/nianticlabs/wavelet-monodepth.svg) :fire:
- [[CVPR](https://openaccess.thecvf.com/content/CVPR2021/papers/Watson_The_Temporal_Opportunist_Self-Supervised_Multi-Frame_Monocular_Depth_CVPR_2021_paper.pdf)] The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth [[code](https://github.com/nianticlabs/manydepth)]![Github stars](https://img.shields.io/github/stars/nianticlabs/manydepth.svg) :fire:
- [[TIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9405457)] Unsupervised Monocular Depth Estimation via
Recursive Stereo Distillation
- [[TIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9416235)] MLDA-Net: Multi-Level Dual Attention-Based Network for Self-Supervised Monocular Depth Estimation
- [[TIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9366926)] Joint Depth and Defocus Estimation From a Single
Image Using Physical Consistency
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8865619)] Deep Depth from Uncalibrated Small Motion Clip
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9018142)] DENAO: Monocular Depth Estimation Network With Auxiliary Optical Flow


## 2020

- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Guizilini_3D_Packing_for_Self-Supervised_Monocular_Depth_Estimation_CVPR_2020_paper.pdf)] 3D Packing for Self-Supervised Monocular Depth Estimation [[code](https://github.com/TRI-ML/packnet-sfm)]![Github starts](https://img.shields.io/github/stars/TRI-ML/packnet-sfm.svg) :fire::star: 
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Johnston_Self-Supervised_Monocular_Trained_Depth_Estimation_Using_Self-Attention_and_Discrete_Disparity_CVPR_2020_paper.pdf)] Self-supervised Monocular Trained Depth Estimation using Self-attention and Discrete Disparity Volume [[code](https://github.com/sjsu-smart-lab/Self-supervised-Monocular-Trained-Depth-Estimation-using-Self-attention-and-Discrete-Disparity-Volum)]![Github starts](https://img.shields.io/github/stars/sjsu-smart-lab/Self-supervised-Monocular-Trained-Depth-Estimation-using-Self-attention-and-Discrete-Disparity-Volum.svg)
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Spencer_DeFeat-Net_General_Monocular_Depth_via_Simultaneous_Unsupervised_Representation_Learning_CVPR_2020_paper.pdf)] DeFeat-Net: General Monocular Depth via Simultaneous Unsupervised Representation Learning [[code](https://github.com/jspenmar/DeFeat-Net)]![Github starts](https://img.shields.io/github/stars/jspenmar/DeFeat-Net.svg)
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_The_Edge_of_Depth_Explicit_Constraints_Between_Segmentation_and_Depth_CVPR_2020_paper.pdf)] The Edge of Depth: Explicit Constraints between Segmentation and Depth [[code](https://github.com/TWJianNuo/EdgeDepth-Release)]![Github starts](https://img.shields.io/github/stars/TWJianNuo/EdgeDepth-Release.svg)
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_Towards_Better_Generalization_Joint_Depth-Pose_Learning_Without_PoseNet_CVPR_2020_paper.pdf)] Towards Better Generalization: Joint Depth-Pose Learning without PoseNet [[code](https://github.com/B1ueber2y/TrianFlow)]![Github starts](https://img.shields.io/github/stars/B1ueber2y/TrianFlow.svg) :fire:
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Online_Depth_Learning_Against_Forgetting_in_Monocular_Videos_CVPR_2020_paper.pdf)] Online Depth Learning against Forgetting in Monocular Videos
- [[CVPR](https://openaccess.thecvf.com/content_CVPR_2020/papers/Poggi_On_the_Uncertainty_of_Self-Supervised_Monocular_Depth_Estimation_CVPR_2020_paper.pdf)] On the uncertainty of self-supervised monocular depth estimation [[code](https://github.com/mattpoggi/mono-uncertainty)]![Github starts](https://img.shields.io/github/stars/mattpoggi/mono-uncertainty.svg) :fire:
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750052.pdf)] S<sup>3</sup>Net: Semantic-Aware Self-supervised Depth Estimation with Monocular Videos and Synthetic Data
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730443.pdf)] Unsupervised Monocular Depth Estimation for Night-time Images using Adversarial Domain Feature Adaptation
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710579.pdf)] Guiding Monocular Depth Estimation Using Depth-Attention Volume
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690205.pdf)] P<sup>2</sup>Net: Patch-match and Plane-regularization for Unsupervised Indoor Depth Estimation [[code](https://github.com/svip-lab/Indoor-SfMLearner)]![Github starts](https://img.shields.io/github/stars/svip-lab/Indoor-SfMLearner.svg)
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123690205.pdf)] Self-Supervised Monocular Depth Estimation Solving the Dynamic Object Problem by Semantic Guidance [[code](https://github.com/ifnspaml/SGDepth)]![Github starts](https://img.shields.io/github/stars/ifnspaml/SGDepth.svg) :fire:
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123640562.pdf)] Feature-metric Loss for Self-supervised Learning of Depth and Egomotion [[code](https://github.com/sconlyshootery/FeatDepth)]![Github starts](https://img.shields.io/github/stars/sconlyshootery/FeatDepth.svg) :fire:
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620766.pdf)] Multi-Loss Rebalancing Algorithm for Monocular Depth Estimation
- [[ECCV](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590086.pdf)] Improving Monocular Depth Estimation by Leveraging Structural Awareness and Complementary Datasets
- [[TIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8972902)] Adversarial Learning for Joint Optimization of Depth and Ego-Motion
- [[TIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9139261)] An Object Context Integrated Network for JointLearning of Depth and Optical Flow
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8765412)] Confidence Propagation through CNNs for Guided Sparse Depth Regression
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8869936)] Learning Depth with Convolutional Spatial Propagation Network
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8846077)] Progressive_Fusion for Unsupervised Binocular Depth Estimation Using Cycled Networks
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8807270)] Semi-Supervised Adversarial Monocular Depth Estimation
- [[TPAMI](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8834825)] Unsupervised Domain Adaptation for Depth Prediction from Images
- [[NeuIPS](https://arxiv.org/pdf/2008.03633v2.pdf)] Forget About the LiDAR: Self-Supervised DepthEstimators with MED Probability Volumes [[code](https://github.com/JuanLuisGonzalez/FAL_net)]![Github starts](https://img.shields.io/github/stars/JuanLuisGonzalez/FAL_net.svg)
- [[NeuIPS](https://arxiv.org/pdf/2006.08602.pdf)] Targeted Adversarial Perturbations for Monocular Depth Prediction [[code](https://github.com/alexklwong/targeted-adversarial-perturbations-monocular-depth)]![Github starts](https://img.shields.io/github/stars/alexklwong/targeted-adversarial-perturbations-monocular-depth.svg)


## 2019

- [[ICCV](https://arxiv.org/pdf/1806.01260)] Digging Into Self-Supervised Monocular Depth Estimation [[code](https://github.com/nianticlabs/monodepth2)]![Github stars](https://img.shields.io/github/stars/nianticlabs/monodepth2.svg) :fire::star: 
- [[ICCV](https://arxiv.org/pdf/1904.04998.pdf)]Depth from Videos in the Wild: Unsupervised Monocular Depth Learning from Unknown Cameras[[code](https://github.com/google-research/google-research/tree/master/depth_and_motion_learning)]![Github stars](https://img.shields.io/github/stars/google-research/google-research.svg) :fire::star: 


## 2017

- [[CVPR](https://openaccess.thecvf.com/content_cvpr_2017/papers/Zhou_Unsupervised_Learning_of_CVPR_2017_paper.pdf)] [[vidoe](https://www.youtube.com/watch?v=HWu39YkGKvI)]Unsupervised Learning of Depth and Ego-Motion from Video [[tensorflow](https://github.com/tinghuiz/SfMLearner)] ![Github stars](https://img.shields.io/github/stars/tinghuiz/SfMLearner.svg)[[pytorch](https://github.com/ClementPinard/SfmLearner-Pytorch)]![Github stars](https://img.shields.io/github/stars/ClementPinard/SfmLearner-Pytorch.svg):fire::star: â€‹

